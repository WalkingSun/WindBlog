---
layout: blog
title: redis数据结构及场景【draft】
categories: [redis, 事务]
description: 了解redis的数据结构，应用场景
keywords: redis, 事务, 乐观锁
cnblogsClass: \[Markdown\],\[随笔分类\]服务器,\[随笔分类\]数据库
oschinaClass: \[Markdown\],数据库,服务器,日常记录
csdnClass: \[Markdown\]
163Class: \[Markdown\]
51ctoClass: \[Markdown\]
chinaunixClass: \[Markdown\]
sinaClass: \[Markdown\]
---

# 数据结构

string、hash、list、set、zset、bitmap、HyperLogLog、bf（布隆过滤器）、stream


常用的前5种类型不做细究，来看看后面一个的结构及用法。

## bitmap
在我们平时开发过程中，会有一些 bool 型数据需要存取，比如用户一年的签到记录，签了是 1，没签是 0，要记录 365 天。如果使用普通的 key/value，每个用户要记录 365 个，当用户上亿的时候，需要的存储空间是惊人的。
为了解决这个问题，Redis 提供了位图数据结构，这样每天的签到记录只占据一个位，365 天就是 365 个位，46 个字节 (一个稍长一点的字符串) 就可以完全容纳下，这就大大节约了存储空间。

![image](https://raw.githubusercontent.com/WalkingSun/WindBlog/gh-pages/images/blog/1566527501259-5ba9e6b2-e3dd-4c17-9c23-206c28703b6c.gif)

位图不是特殊的数据结构，它的内容其实就是普通的字符串，也就是 byte 数组。我们可以使用普通的 get/set 直接获取和设置整个位图的内容，也可以使用位图操作 getbit/setbit 等将 byte 数组看成「位数组」来处理。

当我们要统计月活的时候，因为需要去重，需要使用 set 来记录所有活跃用户的 id，这非常浪费内存。这时就可以考虑使用位图来标记用户的活跃状态。每个用户会都在这个位图的一个确定位置上，0 表示不活跃，1 表示活跃。然后到月底
遍历一次位图就可以得到月度活跃用户数。不过这个方法也是有条件的，那就是 userid 是整数连续的，并且活跃占比较高，否则可能得不偿失。

### 基本使用
Redis 的位数组是自动扩展，如果设置了某个偏移位置超出了现有的内容范围，就会自动将位数组进行零扩充。

来了解几个命令：
- setbit  key offset value 对 key 所储存的字符串值，设置或清除指定偏移量上的位(bit)。
- getbit  key offset   对 key 所储存的字符串值，获取指定偏移量上的位(bit)。
- BITCOUNT key [start] [end] 计算给定字符串中，被设置为 1 的比特位的数量。
```
127.0.0.1:6379> setbit s 1 1
(integer) 0
127.0.0.1:6379> setbit s 2 1
(integer) 0
127.0.0.1:6379> setbit s 4 1
(integer) 0
127.0.0.1:6379> setbit s 9 1
(integer) 0
127.0.0.1:6379> setbit s 10 1
(integer) 0
127.0.0.1:6379> setbit s 13 1
(integer) 0
127.0.0.1:6379> setbit s 15 1
(integer) 0
127.0.0.1:6379> get s
"he"   #01101000 01100101  
127.0.0.1:6379> getbit s 1
(integer) 1
127.0.0.1:6379> BITCOUNT s
(integer) 7

```

## HyperLogLog

### 概念
先来了解下基数计数，基数计数是用于统计一个集合中不重复的元素个数，比如统计页面的UV或者在线的用户数、注册IP数等。

你会如何实现？简单的做法就是记录集合中的所有不重复的集合S，新来元素x，首先判断x是不是在S中，若不再，集合添加x，反之不记录。常用的数据结构SET就可以实现。

但是存在问题，数据量越来越大，会造成什么问题？
- 统计的数据量变大时，相应的存储内存会线性增长；
- 当集合S越大时，判断x元素是否在集合S中的查询的成本会越来越大；

常用的基数计数有三种：B+树、bitmap、概率算法。
- B+树。插入、查找效率比较高。但是没有解决内存空间的问题。
- bitmap。基数计数将每一个元素对应到bit数组的其中一位，比如bit数组10010101，代表[1,4,6,8 ]。新加入的元素只需要已有的bit数组会让新加入的元素进行按位或计算。此种方式大大减少内存，如果存储1亿数据的话，大概只需要10000000000/8/1024=12M的内存。
相比B+树节省很多空间。但某些大数据场景，如果有10000个对象有1亿数据，则需要120G内存，特定场景下内存的消耗还是蛮大的。
- 概率算法，概率算法是通过牺牲准确率来换取空间，对于不要求绝对准确率的场景下，概率算法是一种不错的选择，因为概率算法不直接存储数据集合本身，通过一定的概率统计方法预估基数值，同时保证误差在一定范围内，这种方式可以大大减少
内存。HyperLogLog就是概率算法的一种实现。

### 原理
HyperLogLog原理思路是通过给定n个的元素集合，记录集合中数字的比特串第一个1出现位置的做大值k，也可以理解为统计二进制低位连续为零的最大个数。通过k值可以估算集合中不重复原色的数量m，m近似等于2^k。

下图来源于网络，通过给定一定数量的用户User，通过Hash得到一串Bitstring，记录其中最大连续零位的计数为4，User的不重复个数为 2 ^ 4 = 16.
![image](https://raw.githubusercontent.com/WalkingSun/WindBlog/gh-pages/images/blog/QQ20191118-220433.png)


### redis用法

主要涉及三个命令
- pfadd 增加一个元素到key中
- pfcount 统计key中不重复元素的个数
- Pfmerge 合并多个Key中的元素
pfadd 和 pfcount，根据字面意义很好理解，一个是增加计数，一个是获取计数。pfadd 用法和 set 集合的 sadd 是一样的，来一个用户 ID，就将用户 ID 塞进去就是。pfcount 和 scard 用法是一样的，直接获取计数值。

> pfmerge 适合什么场合用？
HyperLogLog 除了上面的 pfadd 和 pfcount 之外，还提供了第三个指令 pfmerge，用于将多个 pf 计数值累加在一起形成一个新的 pf 值。
比如在网站中我们有两个内容差不多的页面，运营说需要这两个页面的数据进行合并。其中页面的 UV 访问量也需要合并，那这个时候 pfmerge 就可以派上用场了


### 注意事项
HyperLogLog 这个数据结构不是免费的，不是说使用这个数据结构要花钱，它需要占据一定 12k 的存储空间，所以它不适合统计单个用户相关的数据。如果你的用户上亿，可以算算，这个空间成本是非常惊人的。但是相比 set 存储方案，HyperLogLog 所使用的空间那真是可以使用千斤对比四两来形容了。
不过你也不必过于担心，因为 Redis 对 HyperLogLog 的存储进行了优化，在计数比较小时，它的存储空间采用稀疏矩阵存储，空间占用很小，仅仅在计数慢慢变大，稀疏矩阵占用空间渐渐超过了阈值时才会一次性转变成稠密矩阵，才会占用 12k 的空间。

> 思考：如果你负责开发维护一个大型的网站，有一天老板找产品经理要网站每个网页每天的 UV 数据，然后让你来开发这个统计模块，你会如何实现？

其实老板需要的数据又不需要太精确，105w 和 106w 这两个数字对于老板们来说并没有多大区别，使用HyperLogLog轻松实现。

## 布隆过滤器



